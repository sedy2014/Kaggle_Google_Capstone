{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Audio Restoration Agent using Gemini and Gradio\n",
    "\n",
    "This notebook implements an interactive web application where users can upload audio files, ask questions about them (like \"What is the noise floor?\"), and request noise reduction (like \"Remove noise by 5 dB\"). The application uses the Google Gemini API for natural language understanding and function calling, `librosa` and `noisereduce` for audio processing, and `Gradio` for the user interface.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Conversational Interface:** Interact with the system using natural language queries.\n",
    "*   **Audio Upload:** Supports uploading audio files (WAV recommended).\n",
    "*   **Noise Floor Analysis:** Estimates and reports the background noise level in dB using the `get_noise_floor` function.\n",
    "*   **Noise Reduction:** Applies noise reduction using spectral gating via the `reduce_noise_by_db` function, controlled by the user's request (e.g., \"by 5 dB\").\n",
    "*   **Gemini Function Calling:** Leverages Gemini's ability to understand the user's intent and automatically call the appropriate Python function (`get_noise_floor` or `reduce_noise_by_db`) with the correct parameters.\n",
    "*   **Visual Feedback:** Displays spectrograms of the original and denoised audio for visual comparison.\n",
    "*   **Audio Playback:** Allows playback of the original (via re-upload if needed) and denoised audio.\n",
    "\n",
    "**Potential Future Enhancements:**\n",
    "\n",
    "*   **Support for More Formats:** Improve audio loading robustness (e.g., ensure FFmpeg is reliably used) to handle MP3, M4A, etc.\n",
    "*   **Advanced Noise Reduction:** Integrate more sophisticated denoising models (e.g., deep learning based) or offer different algorithm choices.\n",
    "*   **Parameter Tuning:** Allow users to fine-tune noise reduction parameters via the UI (e.g., aggressiveness, frequency range).\n",
    "*   **Streaming Audio:** Support processing real-time audio streams.\n",
    "*   **Deployment:** Package the application for deployment (e.g., using Docker, Hugging Face Spaces).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T03:19:54.340671Z",
     "iopub.status.busy": "2025-04-20T03:19:54.340142Z",
     "iopub.status.idle": "2025-04-20T03:19:58.988876Z",
     "shell.execute_reply": "2025-04-20T03:19:58.988146Z",
     "shell.execute_reply.started": "2025-04-20T03:19:54.340653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Remove unused conflicting packages\n",
    "#!pip uninstall -qqy jupyterlab kfp 2>/dev/null\n",
    "# Install specific google-genai version used in the original notebook\n",
    "!pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "*   This cell installs the necessary Python libraries required for the application.\n",
    "*   `google-genai`: The official Google Gemini SDK for Python.\n",
    "*   `gradio`: Used to create the interactive web UI.\n",
    "*   `librosa`: A powerful library for audio analysis (loading, spectrograms).\n",
    "*   `matplotlib`: Used by librosa for plotting spectrograms.\n",
    "*   `noisereduce`: Performs the noise reduction algorithm.\n",
    "*   `soundfile`: Used by librosa (and directly) for reading/writing audio files (often needs system libraries like `libsndfile`).\n",
    "*   `numpy`: Fundamental package for numerical operations.\n",
    "*   `ffmpeg-python`: Python bindings for FFmpeg. `librosa`'s fallback audio loading mechanism (`audioread`) often requires the FFmpeg multimedia framework to be installed on your system to handle various audio formats (like MP3 or certain WAV encodings). You might need to install FFmpeg separately using your system's package manager (e.g., `sudo apt update && sudo apt install ffmpeg` on Debian/Ubuntu, `brew install ffmpeg` on macOS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T03:19:58.990140Z",
     "iopub.status.busy": "2025-04-20T03:19:58.989979Z",
     "iopub.status.idle": "2025-04-20T03:20:07.219943Z",
     "shell.execute_reply": "2025-04-20T03:20:07.219178Z",
     "shell.execute_reply.started": "2025-04-20T03:19:58.990125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "# Uncomment the line below to run the installation if needed\n",
    "!pip install  gradio librosa matplotlib noisereduce soundfile numpy ffmpeg-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "*   Imports all the necessary modules from the installed libraries for use in the script.\n",
    "*   `os`: For interacting with the operating system (e.g., setting environment variables, path operations).\n",
    "*   `gradio` as `gr`: For building the user interface.\n",
    "*   `numpy` as `np`: For numerical calculations.\n",
    "*   `librosa`, `librosa.display`: For audio loading and spectrogram visualization.\n",
    "*   `matplotlib.pyplot` as `plt`: For finalizing and customizing plots.\n",
    "*   `noisereduce` as `nr`: For the noise reduction function.\n",
    "*   `soundfile` as `sf`: For writing audio files.\n",
    "*   `google.genai` as `genai`, `google.genai.types`: For interacting with the Gemini API and its specific types.\n",
    "*   `traceback`: For getting detailed error information in exception handlers.\n",
    "*   `time`: For generating unique timestamps for filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:07.221010Z",
     "iopub.status.busy": "2025-04-20T03:20:07.220774Z",
     "iopub.status.idle": "2025-04-20T03:20:15.085008Z",
     "shell.execute_reply": "2025-04-20T03:20:15.084369Z",
     "shell.execute_reply.started": "2025-04-20T03:20:07.220984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import traceback # Import traceback for better error details\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Gemini Client\n",
    "\n",
    "*   Sets the Google API key from an environment variable. **Remember to replace `\"YOUR_GEMINI_API_KEY\"` with your actual key.**\n",
    "*   Creates the Gemini API client instance (`genai.Client`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.086636Z",
     "iopub.status.busy": "2025-04-20T03:20:15.086254Z",
     "iopub.status.idle": "2025-04-20T03:20:15.316474Z",
     "shell.execute_reply": "2025-04-20T03:20:15.315851Z",
     "shell.execute_reply.started": "2025-04-20T03:20:15.086621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Kaggle, API key loaded from Kaggle Secrets.\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "print(\"Running on Kaggle, API key loaded from Kaggle Secrets.\")\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Audio Analysis Tool Functions\n",
    "\n",
    "These Python functions will be made available to the Gemini model. The Gemini SDK's function calling feature allows the model to decide when to execute these functions based on the user's query.\n",
    "\n",
    "#### `get_noise_floor(audio_path: str) -> dict`\n",
    "\n",
    "*   **Purpose:** Estimates the background noise level (noise floor) of an audio file.\n",
    "*   **Input:** `audio_path` (string) - The absolute path to the audio file.\n",
    "*   **Process:**\n",
    "    1.  Checks if the provided `audio_path` actually exists. Returns an error dictionary if not.\n",
    "    2.  Loads the audio file using `librosa.load(audio_path, sr=None)`. `sr=None` preserves the original sample rate. Librosa might use `soundfile` or fallback to `audioread` (which may need FFmpeg).\n",
    "    3.  Handles cases where the audio file is empty or contains only silence.\n",
    "    4.  Estimates the noise floor amplitude: It calculates the 10th percentile of the *absolute* values of the audio samples. This is a simple heuristic assuming that the quietest 10% of the signal largely represents background noise.\n",
    "    5.  Converts the noise amplitude to decibels (dB) relative to the maximum possible amplitude (0 dBFS). The formula used is $$ \\text{dB} = 10 \\log_{10}(\\text{amplitude}^2 + 10^{-10}) $$. A small value ($$10^{-10}$$) is added before the logarithm for numerical stability, preventing $$ \\log_{10}(0) $$.\n",
    "*   **Output:** A dictionary containing either the calculated noise floor (`{'noise_floor_db': float_value}`) or an error message (`{'noise_floor_db': None, 'error': '...'}`).\n",
    "*   **Gemini Integration:** The function's docstring and type hints allow the Gemini SDK to automatically create a schema. Gemini will call this function when the user asks a question like \"What is the noise floor?\".\n",
    "\n",
    "#### `reduce_noise_by_db(audio_path: str, reduction_db: int) -> dict`\n",
    "\n",
    "*   **Purpose:** Reduces background noise in an audio file using a spectral gating algorithm provided by the `noisereduce` library.\n",
    "*   **Inputs:**\n",
    "    *   `audio_path` (string): The absolute path to the input audio file.\n",
    "    *   `reduction_db` (integer): The desired amount of noise reduction in decibels (dB). A higher value means more aggressive reduction.\n",
    "*   **Process:**\n",
    "    1.  Checks if the input `audio_path` exists.\n",
    "    2.  Loads the audio file using `librosa.load`.\n",
    "    3.  Handles empty audio files.\n",
    "    4.  Estimates the noise profile: It takes the first 0.5 seconds of the audio (`noise_clip`) as representative of the background noise. Handles cases where the audio is shorter than 0.5 seconds or if the noise clip contains non-finite values (e.g., `NaN`, `inf`).\n",
    "    5.  Applies noise reduction using `noisereduce.reduce_noise`:\n",
    "        *   `y`: The full audio signal array.\n",
    "        *   `sr`: The audio sample rate.\n",
    "        *   `y_noise`: The noise profile estimated from `noise_clip`.\n",
    "        *   `prop_decrease`: Controls the aggressiveness of the noise reduction. The `noisereduce` library expects a proportion (0 to 1), so the input `reduction_db` is scaled (approximately `reduction_db / 20`) and clamped between 0 and 1.\n",
    "    6.  Generates a unique output filename using a timestamp (`denoised_{timestamp}.wav`) and constructs its absolute path in the current working directory.\n",
    "    7.  Saves the noise-reduced audio (`reduced`) to the new file using `soundfile.write`.\n",
    "    8.  Verifies that the output file was created successfully and is not empty using `os.path.exists` and `os.path.getsize`.\n",
    "*   **Output:** A dictionary containing either the absolute path to the denoised file (`{'denoised_path': '/path/to/denoised_....wav'}`) or an error message (`{'denoised_path': None, 'error': '...'}`).\n",
    "*   **Gemini Integration:** Gemini calls this function when the user asks to \"remove noise\", \"denoise\", etc., inferring the `reduction_db` amount from the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.317379Z",
     "iopub.status.busy": "2025-04-20T03:20:15.317132Z",
     "iopub.status.idle": "2025-04-20T03:20:15.327269Z",
     "shell.execute_reply": "2025-04-20T03:20:15.326442Z",
     "shell.execute_reply.started": "2025-04-20T03:20:15.317358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Audio Analysis Functions (for Gemini Function Calling) ---\n",
    "\n",
    "def get_noise_floor(audio_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the noise floor (in dB) of the given audio file.\n",
    "    The noise floor is estimated based on the 10th percentile amplitude.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Absolute path to the audio file (wav recommended).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'noise_floor_db' as float, or 'error' on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the file exists before trying to load\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"[get_noise_floor] Error: File not found at specified path: {audio_path}\")\n",
    "            return {\"noise_floor_db\": None, \"error\": f\"File not found: {audio_path}\"}\n",
    "\n",
    "        # Load audio using librosa (sr=None preserves original sample rate)\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Handle empty or silent audio\n",
    "        if y.size == 0 or np.all(y == 0):\n",
    "            print(f\"[get_noise_floor] Warning: Audio file is empty or silent: {audio_path}\")\n",
    "            return {\"noise_floor_db\": -np.inf} # Represent silence as negative infinity dB\n",
    "\n",
    "        # Estimate noise floor amplitude (10th percentile of absolute signal)\n",
    "        noise_amplitude = np.percentile(np.abs(y), 10)\n",
    "\n",
    "        # Convert amplitude to dB (relative to 1.0)\n",
    "        # Add epsilon (1e-10) for numerical stability to avoid log10(0)\n",
    "        noise_floor_db = 10 * np.log10(noise_amplitude**2 + 1e-10)\n",
    "\n",
    "        # print(f\"[get_noise_floor] Calculated noise floor for {os.path.basename(audio_path)}: {noise_floor_db:.2f} dB\") # Optional debug log\n",
    "        return {\"noise_floor_db\": float(noise_floor_db)}\n",
    "    except Exception as e:\n",
    "        # Log and return error if any step fails\n",
    "        print(f\"[get_noise_floor] ERROR processing {os.path.basename(audio_path)}: {e}\")\n",
    "        return {\"noise_floor_db\": None, \"error\": str(e)}\n",
    "\n",
    "def reduce_noise_by_db(audio_path: str, reduction_db: int) -> dict:\n",
    "    \"\"\"\n",
    "    Reduce noise in the audio file by a specified dB amount using spectral gating.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Absolute path to the input audio file (wav recommended).\n",
    "        reduction_db: Amount of noise reduction desired in dB (e.g., 5, 10).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with 'denoised_path' (absolute path to output wav file), or 'error'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if input file exists\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"[reduce_noise_by_db] Error: Input file not found: {audio_path}\")\n",
    "            return {\"denoised_path\": None, \"error\": f\"Input file not found: {audio_path}\"}\n",
    "\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Handle empty audio\n",
    "        if y.size == 0:\n",
    "            print(f\"[reduce_noise_by_db] Warning: Input audio is empty: {audio_path}\")\n",
    "            return {\"denoised_path\": None, \"error\": \"Input audio is empty\"}\n",
    "\n",
    "        # Estimate noise profile from the beginning of the audio (e.g., first 0.5 seconds)\n",
    "        noise_clip_len = min(len(y), int(sr*0.5)) # Use min to handle short audio\n",
    "        if noise_clip_len == 0:\n",
    "             print(f\"[reduce_noise_by_db] Warning: Audio too short for noise profiling: {audio_path}\")\n",
    "             # If audio is extremely short, maybe just return original or error\n",
    "             return {\"denoised_path\": audio_path, \"error\": \"Audio too short for noise profiling\"}\n",
    "        noise_clip = y[:noise_clip_len]\n",
    "\n",
    "        # Ensure noise profile contains valid numbers\n",
    "        if not np.all(np.isfinite(noise_clip)):\n",
    "             print(f\"[reduce_noise_by_db] Error: Non-finite values detected in noise clip for {audio_path}\")\n",
    "             return {\"denoised_path\": None, \"error\": \"Non-finite values detected in noise clip\"}\n",
    "\n",
    "        # Perform noise reduction using noisereduce library\n",
    "        # `prop_decrease` controls reduction amount (0-1 scale), map from dB and clamp\n",
    "        prop_decrease = min(max(reduction_db / 20.0, 0.0), 1.0) # Clamp between 0 and 1\n",
    "        print(f\"[reduce_noise_by_db] Applying noise reduction with prop_decrease={prop_decrease:.2f} (from {reduction_db} dB)\")\n",
    "        reduced_audio = nr.reduce_noise(y=y, sr=sr, y_noise=noise_clip, prop_decrease=prop_decrease)\n",
    "\n",
    "        # Generate unique output filename and absolute path in the current directory\n",
    "        timestamp = int(time.time())\n",
    "        out_filename = f\"denoised_{timestamp}.wav\"\n",
    "        out_path = os.path.join(os.getcwd(), out_filename) # Use absolute path\n",
    "\n",
    "        # Save the denoised audio\n",
    "        sf.write(out_path, reduced_audio, sr)\n",
    "\n",
    "        # Verify file was saved successfully\n",
    "        if os.path.exists(out_path) and os.path.getsize(out_path) > 0:\n",
    "            print(f\"[reduce_noise_by_db] Noise reduction successful. Saved to: {out_path} (Size: {os.path.getsize(out_path)} bytes)\")\n",
    "            return {\"denoised_path\": out_path} # Return the absolute path\n",
    "        else:\n",
    "            # Handle file saving errors\n",
    "            error_msg = f\"Failed to write or created empty denoised file: {out_path}\"\n",
    "            print(f\"[reduce_noise_by_db] ERROR: {error_msg}\")\n",
    "            return {\"denoised_path\": None, \"error\": error_msg}\n",
    "    except Exception as e:\n",
    "        # Log and return error if any step fails\n",
    "        print(f\"[reduce_noise_by_db] ERROR processing {os.path.basename(audio_path)}: {e}\")\n",
    "        # traceback.print_exc() # Uncomment for full traceback during debugging\n",
    "        return {\"denoised_path\": None, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Spectrogram Plotting Function\n",
    "\n",
    "*   **`plot_spectrogram(audio_path, title)`**:\n",
    "    *   Takes an audio file path and a title string.\n",
    "    *   Checks if the path is valid and the file exists and is not empty.\n",
    "    *   Loads the audio using `librosa.load`.\n",
    "    *   Calculates the Short-Time Fourier Transform (STFT) using `librosa.stft`.\n",
    "    *   Converts the STFT magnitude to decibels using `librosa.amplitude_to_db`.\n",
    "    *   Uses `librosa.display.specshow` to create a spectrogram plot (frequency vs. time, color intensity represents dB level).\n",
    "    *   Adds a title and color bar.\n",
    "    *   Uses `plt.close(fig)` to prevent the plot from displaying directly in the notebook output (Gradio will handle displaying it).\n",
    "    *   Returns the `matplotlib.figure.Figure` object for Gradio to display, or `None` if an error occurred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.328199Z",
     "iopub.status.busy": "2025-04-20T03:20:15.327980Z",
     "iopub.status.idle": "2025-04-20T03:20:15.343419Z",
     "shell.execute_reply": "2025-04-20T03:20:15.342842Z",
     "shell.execute_reply.started": "2025-04-20T03:20:15.328180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Spectrogram Plotting Function ---\n",
    "\n",
    "def plot_spectrogram(audio_path, title=\"Spectrogram\"):\n",
    "    \"\"\"\n",
    "    Generates a spectrogram plot for the given audio file.\n",
    "\n",
    "    Args:\n",
    "        audio_path: Absolute path to the audio file.\n",
    "        title: Title for the plot.\n",
    "\n",
    "    Returns:\n",
    "        A matplotlib Figure object containing the plot, or None on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input path and file existence/size\n",
    "        if not audio_path or not isinstance(audio_path, str) or not os.path.exists(audio_path):\n",
    "             print(f\"[plot_spectrogram] Skipped: File not found or path invalid: {audio_path}\")\n",
    "             return None\n",
    "        # Check file size to avoid errors with empty files\n",
    "        if os.path.getsize(audio_path) == 0:\n",
    "            print(f\"[plot_spectrogram] Skipped: Audio file is empty: {audio_path}\")\n",
    "            return None\n",
    "\n",
    "        # print(f\"[plot_spectrogram] Plotting: {audio_path}\") # Optional debug log\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "        # Handle empty loaded audio data (should be caught by size check, but belt-and-suspenders)\n",
    "        if y.size == 0:\n",
    "            print(f\"[plot_spectrogram] Skipped: Loaded audio data is empty after load: {audio_path}\")\n",
    "            return None\n",
    "\n",
    "        # Compute STFT and convert to dB scale (log magnitude)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "\n",
    "        # Create the plot using matplotlib\n",
    "        fig, ax = plt.subplots(figsize=(8, 3)) # Adjust figsize as needed\n",
    "        # Display spectrogram with log frequency axis\n",
    "        img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', ax=ax)\n",
    "        ax.set(title=title) # Set plot title\n",
    "        fig.colorbar(img, ax=ax, format=\"%+2.0f dB\") # Add color bar showing dB scale\n",
    "        plt.tight_layout() # Adjust layout\n",
    "\n",
    "        # IMPORTANT: Close the plot figure object to prevent duplicate display\n",
    "        plt.close(fig)\n",
    "\n",
    "        # print(f\"[plot_spectrogram] Success for: {audio_path}\") # Optional debug log\n",
    "        return fig # Return the figure object for Gradio\n",
    "    except Exception as e:\n",
    "        # Log errors during plotting\n",
    "        print(f\"[plot_spectrogram] ERROR plotting spectrogram for {os.path.basename(audio_path)}: {e}\")\n",
    "        # traceback.print_exc() # Uncomment for detailed traceback during debugging\n",
    "        return None # Return None if plotting fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Main Agent Logic\n",
    "\n",
    "*   **`agent(audio, user_query)`**: This is the core function that Gradio calls when the user clicks \"Submit\".\n",
    "    *   **Inputs:**\n",
    "        *   `audio`: The audio data uploaded by the user (as a tuple `(sample_rate, numpy_array)` because `type=\"numpy\"` is used in `gr.Audio`).\n",
    "        *   `user_query`: The text entered by the user.\n",
    "    *   **Process:**\n",
    "        1.  Performs initial checks: verifies the Gemini client is initialized and the audio input is valid.\n",
    "        2.  Generates a unique input filename and saves the uploaded audio data to an absolute path using `soundfile.write`. Checks if saving was successful.\n",
    "        3.  Defines the list of available Python tool functions (`tools = [get_noise_floor, reduce_noise_by_db]`).\n",
    "        4.  Defines the `system_instruction` to guide the Gemini model on how to behave and use the tools.\n",
    "        5.  Constructs the prompt for Gemini, explicitly including the absolute path to the saved input audio file.\n",
    "        6.  Prepares the `GenerateContentConfig` object, passing the `tools` list and the `system_instruction`.\n",
    "        7.  Calls the Gemini API using `client.models.generate_content`, providing the model name, the user prompt (`contents`), and the `config`. This triggers the automatic function calling process if needed.\n",
    "        8.  Initializes variables for the output text, denoised audio path, and spectrogram plots. Plots the original spectrogram immediately using the absolute input path.\n",
    "        9.  **Parses Function Call Results from History:** Iterates through the `response.automatic_function_calling_history`. This history contains the sequence of model turns and tool executions. It looks specifically for parts with a `function_response` added back by the SDK (usually under the `user` role in the history).\n",
    "        10. If a `function_response` is found, it extracts the nested `result` dictionary (which contains the actual dictionary returned by your Python function, e.g., `{'denoised_path': '...'}`).\n",
    "        11. Based on the function name (`func_name`), it updates the `output_text` by appending the function result, assigns the `denoised_audio_path` (using the absolute path returned by the function), and calls `plot_spectrogram` for the denoised file if applicable. Includes checks for valid results (e.g., path exists).\n",
    "        12. Retrieves the final text generated by the model (after function calls) from `response.candidates`.\n",
    "        13. Includes robust error handling using a `try...except` block around the entire process.\n",
    "    *   **Outputs:** Returns a tuple containing the values needed to update the Gradio output components: `(output_text, orig_spec_plot, denoised_spec_plot, denoised_audio_path)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.344927Z",
     "iopub.status.busy": "2025-04-20T03:20:15.344297Z",
     "iopub.status.idle": "2025-04-20T03:20:15.362077Z",
     "shell.execute_reply": "2025-04-20T03:20:15.361507Z",
     "shell.execute_reply.started": "2025-04-20T03:20:15.344895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Gradio + Gemini Conversational Agent Logic ---\n",
    "\n",
    "def agent(audio, user_query):\n",
    "    \"\"\"\n",
    "    Handles user interaction via Gradio: saves audio, calls Gemini with tools,\n",
    "    parses results, generates plots, and returns outputs for the UI.\n",
    "    \"\"\"\n",
    "    # --- 1. Input Validation & Setup ---\n",
    "    if client is None:\n",
    "        # Check if Gemini client failed to initialize\n",
    "        return \"ERROR: Gemini client not initialized. Please check API Key and restart.\", None, None, None\n",
    "    if audio is None or not isinstance(audio, tuple) or len(audio) != 2:\n",
    "        return \"ERROR: Invalid audio input. Please upload a valid audio file.\", None, None, None\n",
    "\n",
    "    sample_rate, audio_data = audio\n",
    "    if audio_data is None or audio_data.size == 0:\n",
    "        return \"ERROR: Audio data is empty.\", None, None, None\n",
    "\n",
    "    # Generate unique absolute path for the input file\n",
    "    timestamp = int(time.time())\n",
    "    input_audio_filename = f\"input_{timestamp}.wav\"\n",
    "    input_audio_path = os.path.join(os.getcwd(), input_audio_filename) # Use absolute path\n",
    "\n",
    "    # Initialize output variables\n",
    "    output_text = \"Processing...\"\n",
    "    orig_spec_plot = None\n",
    "    denoised_spec_plot = None\n",
    "    denoised_audio_path = None # Store path to the final denoised audio\n",
    "\n",
    "    try:\n",
    "        # --- 2. Save Uploaded Audio ---\n",
    "        print(f\"[agent] Saving uploaded audio to: {input_audio_path}\")\n",
    "        sf.write(input_audio_path, audio_data, sample_rate)\n",
    "        # Verify save operation\n",
    "        if not os.path.exists(input_audio_path) or os.path.getsize(input_audio_path) == 0:\n",
    "             print(f\"[agent] ERROR: Failed to save uploaded audio file to {input_audio_path}\")\n",
    "             return \"[agent] Error: Failed to save uploaded audio file.\", None, None, None\n",
    "        print(f\"[agent] Successfully saved input file.\")\n",
    "\n",
    "        # --- 3. Prepare Gemini API Call ---\n",
    "        tools = [get_noise_floor, reduce_noise_by_db]\n",
    "        system_instruction_text = (\n",
    "            \"You are an audio analysis assistant. Always use the provided tools to answer questions about noise floor or to denoise audio. \"\n",
    "            \"Do not attempt to answer directly—always invoke the relevant function. The audio file path is specified in the user prompt.\"\n",
    "        )\n",
    "        config = types.GenerateContentConfig(\n",
    "            tools=tools,\n",
    "            system_instruction=system_instruction_text\n",
    "        )\n",
    "        # Pass the absolute path to Gemini in the prompt\n",
    "        prompt_for_gemini = f\"{user_query}\\n\\nAudio path: '{input_audio_path}'\"\n",
    "        contents = [{\"role\": \"user\", \"parts\": [{\"text\": prompt_for_gemini}]}]\n",
    "\n",
    "        # --- 4. Call Gemini API ---\n",
    "        print(f\"[agent] Sending request to Gemini for file: {input_audio_path}\")\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-1.5-flash-latest\", # Use a model supporting function calling\n",
    "            contents=contents,\n",
    "            config=config\n",
    "        )\n",
    "        print(f\"[agent] Received response from Gemini.\")\n",
    "\n",
    "        # --- 5. Process Gemini Response ---\n",
    "        # Get the final text response generated by the model (after function calls)\n",
    "        final_text_response = \"\"\n",
    "        if response.candidates and response.candidates[0].content.parts:\n",
    "             final_text_response = \"\".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))\n",
    "        output_text = final_text_response if final_text_response else \"Processing complete.\"\n",
    "\n",
    "        # Plot original spectrogram immediately (using absolute path)\n",
    "        orig_spec_plot = plot_spectrogram(input_audio_path, \"Original Spectrogram\")\n",
    "\n",
    "        # Parse function call results from the automatic history\n",
    "        if hasattr(response, 'automatic_function_calling_history'):\n",
    "            print(f\"[agent] Parsing automatic_function_calling_history...\")\n",
    "            history = response.automatic_function_calling_history\n",
    "            # Iterate through history to find the SDK-added FunctionResponse\n",
    "            for content in reversed(history): # Look from end\n",
    "                 if content.role == 'user' and content.parts: # SDK adds result as 'user' role\n",
    "                     for part in content.parts:\n",
    "                         if hasattr(part, \"function_response\") and part.function_response is not None:\n",
    "                            func_name = part.function_response.name\n",
    "                            func_response_data = part.function_response.response # Outer dict: {'result': {...}}\n",
    "                            print(f\"[agent]   Found FunctionResponse in history for: {func_name}\")\n",
    "\n",
    "                            # Check the expected nested structure: {'result': {actual_dict}}\n",
    "                            if isinstance(func_response_data, dict) and 'result' in func_response_data:\n",
    "                                actual_result = func_response_data.get('result')\n",
    "\n",
    "                                if isinstance(actual_result, dict):\n",
    "                                    # --- Handle get_noise_floor result ---\n",
    "                                    if func_name == \"get_noise_floor\":\n",
    "                                        if 'noise_floor_db' in actual_result and actual_result.get('noise_floor_db') is not None and np.isfinite(actual_result.get('noise_floor_db', np.nan)):\n",
    "                                            noise_db = actual_result['noise_floor_db']\n",
    "                                            output_text += f\"\\n\\n[Function Result]: Noise floor is {noise_db:.2f} dB\"\n",
    "                                        else:\n",
    "                                             error_msg = actual_result.get('error', 'invalid value')\n",
    "                                             output_text += f\"\\n\\n[Function Error]: Could not get noise floor - {error_msg}\"\n",
    "\n",
    "                                    # --- Handle reduce_noise_by_db result ---\n",
    "                                    elif func_name == \"reduce_noise_by_db\":\n",
    "                                        if 'denoised_path' in actual_result:\n",
    "                                            path_value = actual_result.get('denoised_path')\n",
    "                                            # Check if path is valid (non-None string) AND file exists\n",
    "                                            if path_value and isinstance(path_value, str) and os.path.exists(path_value):\n",
    "                                                denoised_audio_path = path_value # Assign the absolute path\n",
    "                                                print(f\"[agent]     Assigned denoised path: {denoised_audio_path}\")\n",
    "                                                if \"Noise reduction successful\" not in output_text: # Append if not already said by model\n",
    "                                                     output_text += f\"\\n\\n[Function Result]: Noise reduction successful. Output path: {os.path.basename(denoised_audio_path)}\"\n",
    "                                                # Plot the denoised spectrogram\n",
    "                                                denoised_spec_plot = plot_spectrogram(denoised_audio_path, \"Denoised Spectrogram\")\n",
    "                                            else:\n",
    "                                                 error_msg = f\"Path '{path_value}' from function invalid or file missing.\"\n",
    "                                                 print(f\"[agent]     ERROR: {error_msg}\")\n",
    "                                                 if \"Noise reduction failed\" not in output_text: output_text += f\"\\n\\n[Function Error]: Noise reduction failed - {error_msg}\"\n",
    "                                        else:\n",
    "                                             error_msg = actual_result.get('error', \"'denoised_path' key missing\")\n",
    "                                             print(f\"[agent]     ERROR: {error_msg}\")\n",
    "                                             if \"Noise reduction failed\" not in output_text: output_text += f\"\\n\\n[Function Error]: Noise reduction failed - {error_msg}\"\n",
    "                                    # If only one function call expected, can break history loop here\n",
    "                                    # break\n",
    "                                # else: print error if actual_result wasn't a dict\n",
    "                                # else: print error if 'result' key missing or not dict\n",
    "        else:\n",
    "             print(\"[agent] No automatic_function_calling_history found or parsed.\")\n",
    "\n",
    "        # --- 6. Final Output Preparation ---\n",
    "        print(\"-\" * 20)\n",
    "        print(\"[agent] Values FINALIZED for Gradio:\")\n",
    "        print(f\"[agent] Output Text: {output_text[:500]}...\")\n",
    "        print(f\"[agent] Original Plot Type: {type(orig_spec_plot)}\")\n",
    "        print(f\"[agent] Denoised Plot Type: {type(denoised_spec_plot)}\")\n",
    "        print(f\"[agent] Denoised Audio Path: {denoised_audio_path}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # Return values in the order expected by Gradio outputs\n",
    "        return output_text, orig_spec_plot, denoised_spec_plot, denoised_audio_path\n",
    "\n",
    "    # --- 7. Error Handling ---\n",
    "    except Exception as e:\n",
    "        # Catch any unexpected errors during the agent execution\n",
    "        error_details = traceback.format_exc()\n",
    "        print(f\"[agent] FATAL ERROR in agent function: {error_details}\")\n",
    "        error_message = f\"An unexpected error occurred: {str(e)}\"\n",
    "        # Return error message to the user\n",
    "        return f\"ERROR: {error_message}\\n\\n(Details logged server-side)\", None, None, None\n",
    "    # --- 8. Cleanup (Optional) ---\n",
    "    finally:\n",
    "        # Example: Delete the temporary input file after processing\n",
    "        try:\n",
    "            if input_audio_path and os.path.exists(input_audio_path):\n",
    "                # os.remove(input_audio_path)\n",
    "                # print(f\"[agent] Cleaned up input file: {input_audio_path}\")\n",
    "                pass # Keeping files for now for inspection\n",
    "        except Exception as clean_e:\n",
    "            print(f\"[agent] Error during cleanup: {clean_e}\")\n",
    "        # Avoid deleting denoised_audio_path here as Gradio needs it\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Gradio User Interface\n",
    "\n",
    "*   Uses `gr.Blocks` for a custom UI layout.\n",
    "*   `gr.Markdown`: Displays introductory text.\n",
    "*   `gr.Row`, `gr.Column`: Organizes components horizontally and vertically.\n",
    "*   `gr.Audio`:\n",
    "    *   Input (`audio_input`): Allows users to upload or record audio. `type=\"numpy\"` makes the callback function (`agent`) receive the audio as a tuple `(sample_rate, numpy_array)`.\n",
    "    *   Output (`denoised_audio`): Displays the processed audio file. `type=\"filepath\"` means it expects an absolute file path string from the `agent` function. `interactive=False` prevents user input on this output component.\n",
    "*   `gr.Textbox`:\n",
    "    *   Input (`user_query`): For the user's text request.\n",
    "    *   Output (`output_text`): Displays the text response from the agent. `interactive=False`.\n",
    "*   `gr.Plot`: Displays the spectrogram images (`orig_spec`, `denoised_spec`) generated by `plot_spectrogram`.\n",
    "*   `gr.Button`: The \"Submit\" button.\n",
    "*   `.click()`: Connects the button click event to the `agent` function, mapping UI inputs (`audio_input`, `user_query`) to the function's arguments and the function's return values to the UI outputs (`output_text`, `orig_spec`, `denoised_spec`, `denoised_audio`) in the specified order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.362913Z",
     "iopub.status.busy": "2025-04-20T03:20:15.362746Z",
     "iopub.status.idle": "2025-04-20T03:20:15.501613Z",
     "shell.execute_reply": "2025-04-20T03:20:15.501005Z",
     "shell.execute_reply.started": "2025-04-20T03:20:15.362895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Gradio User Interface Definition ---\n",
    "\n",
    "# Use gr.Blocks for more layout control\n",
    "with gr.Blocks() as demo:\n",
    "    # Add a title and description using Markdown\n",
    "    gr.Markdown(\"# Conversational Audio Restoration Agent 🎤\")\n",
    "    gr.Markdown(\"Upload audio, ask questions (e.g., 'What is the noise floor?', 'Remove noise by 5 dB'), and see the results.\")\n",
    "\n",
    "    # Arrange components in rows and columns\n",
    "    with gr.Row():\n",
    "        # Left column for user inputs\n",
    "        with gr.Column(scale=1):\n",
    "            # Component for audio upload/recording\n",
    "            audio_input = gr.Audio(\n",
    "                label=\"Upload Audio (WAV recommended)\",\n",
    "                type=\"numpy\" # Provides (sample_rate, data_array) to the backend function\n",
    "            )\n",
    "            # Textbox for the user's natural language query\n",
    "            user_query = gr.Textbox(\n",
    "                label=\"Ask the agent\",\n",
    "                placeholder=\"e.g. 'What is the noise floor?', 'Remove noise by 5 dB'\"\n",
    "            )\n",
    "            # Button to trigger the agent function\n",
    "            btn = gr.Button(\"Submit\", variant=\"primary\") # 'primary' makes it stand out\n",
    "\n",
    "        # Right column for displaying outputs\n",
    "        with gr.Column(scale=2):\n",
    "            # Textbox to show the agent's text response\n",
    "            output_text = gr.Textbox(\n",
    "                label=\"Agent Response\",\n",
    "                lines=5, # Allow multiple lines for longer responses\n",
    "                interactive=False # Output only\n",
    "            )\n",
    "            # Row specifically for the two plots side-by-side\n",
    "            with gr.Row():\n",
    "                 # Placeholder for the original audio spectrogram plot\n",
    "                 orig_spec = gr.Plot(label=\"Original Spectrogram\")\n",
    "                 # Placeholder for the denoised audio spectrogram plot\n",
    "                 denoised_spec = gr.Plot(label=\"Denoised Spectrogram\")\n",
    "            # Component to play back the denoised audio file\n",
    "            denoised_audio = gr.Audio(\n",
    "                label=\"Denoised Audio Output\",\n",
    "                type=\"filepath\", # Expects a file path from the backend function\n",
    "                interactive=False # Output only\n",
    "            )\n",
    "\n",
    "    # Define the action when the button is clicked\n",
    "    btn.click(\n",
    "        fn=agent,                           # The Python function to execute\n",
    "        inputs=[audio_input, user_query],   # Components providing input to the function\n",
    "        outputs=[output_text, orig_spec, denoised_spec, denoised_audio] # Components to update with function's return values\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Launch Gradio App\n",
    "\n",
    "*   Checks if the `client` object was successfully initialized in Step 3.\n",
    "*   If the client is ready, it calls `demo.launch(debug=True)`.\n",
    "    *   `demo.launch()` starts the Gradio web server, making the UI accessible via a local URL (or a public one if `share=True` is used, though be cautious with API keys).\n",
    "    *   `debug=True` provides more detailed error messages directly in the browser console and server logs if something goes wrong within Gradio or the callback function, which is very helpful during development.\n",
    "*   If the client initialization failed, it prints an error message instead of launching the app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T03:20:15.502564Z",
     "iopub.status.busy": "2025-04-20T03:20:15.502404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini client initialized. Launching Gradio app...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://4995b3536ebf629ae2.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4995b3536ebf629ae2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[agent] Saving uploaded audio to: /kaggle/working/input_1745119294.wav\n",
      "[agent] Successfully saved input file.\n",
      "[agent] Sending request to Gemini for file: /kaggle/working/input_1745119294.wav\n",
      "[agent] Received response from Gemini.\n",
      "[agent] Parsing automatic_function_calling_history...\n",
      "[agent]   Found FunctionResponse in history for: get_noise_floor\n",
      "--------------------\n",
      "[agent] Values FINALIZED for Gradio:\n",
      "[agent] Output Text: The noise floor is -57.24 dB.\n",
      "\n",
      "\n",
      "[Function Result]: Noise floor is -57.24 dB...\n",
      "[agent] Original Plot Type: <class 'matplotlib.figure.Figure'>\n",
      "[agent] Denoised Plot Type: <class 'NoneType'>\n",
      "[agent] Denoised Audio Path: None\n",
      "--------------------\n",
      "[agent] Saving uploaded audio to: /kaggle/working/input_1745119320.wav\n",
      "[agent] Successfully saved input file.\n",
      "[agent] Sending request to Gemini for file: /kaggle/working/input_1745119320.wav\n",
      "[reduce_noise_by_db] Applying noise reduction with prop_decrease=1.00 (from 20 dB)\n",
      "[reduce_noise_by_db] Noise reduction successful. Saved to: /kaggle/working/denoised_1745119321.wav (Size: 45102 bytes)\n",
      "[agent] Received response from Gemini.\n",
      "[agent] Parsing automatic_function_calling_history...\n",
      "[agent]   Found FunctionResponse in history for: reduce_noise_by_db\n",
      "[agent]     Assigned denoised path: /kaggle/working/denoised_1745119321.wav\n",
      "--------------------\n",
      "[agent] Values FINALIZED for Gradio:\n",
      "[agent] Output Text: Noise reduced by 20dB. The denoised audio is saved at `/kaggle/working/denoised_1745119321.wav`.\n",
      "\n",
      "\n",
      "[Function Result]: Noise reduction successful. Output path: denoised_1745119321.wav...\n",
      "[agent] Original Plot Type: <class 'matplotlib.figure.Figure'>\n",
      "[agent] Denoised Plot Type: <class 'matplotlib.figure.Figure'>\n",
      "[agent] Denoised Audio Path: /kaggle/working/denoised_1745119321.wav\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Launch Gradio App ---\n",
    "\n",
    "# Check if the Gemini client was initialized successfully before launching the web UI\n",
    "if __name__ == \"__main__\":\n",
    "    # This check prevents running the server if the API key is invalid, for example\n",
    "    if client:\n",
    "        print(\"Gemini client initialized. Launching Gradio app...\")\n",
    "        # Start the Gradio web server interface\n",
    "        # debug=True provides helpful error messages during development\n",
    "        # share=True can create a temporary public link (use with caution regarding API keys/data)\n",
    "        demo.launch(debug=True)\n",
    "    else:\n",
    "        # Inform the user if the app cannot launch due to client initialization failure\n",
    "        print(\"ERROR: Gradio app cannot launch because Gemini client failed to initialize. Please check API key and restart.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
